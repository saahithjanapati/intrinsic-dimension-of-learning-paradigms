{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea526ad-cc57-4ce0-80f0-a4aeffc476d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Datasets to make:\n",
    "\n",
    "- [x] cola\n",
    "- [x] qnli\n",
    "- [x] qqp\n",
    "- [x] sst2\n",
    "- [x] ag_news\n",
    "- [x] commonsense_qa\n",
    "- [x] mnli\n",
    "- [x] mmlu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec8fde1-7dad-4569-882b-80d2c8248a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from promptsource.templates import DatasetTemplates\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "425bceb5-9503-4540-a8a2-f5190f899f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_prompt(dataset_name, config=None, prompt_idx=0):\n",
    "    \"\"\"this function loads a test prompt for a specified dataset to see if promptSource supports it\"\"\"\n",
    "    all_prompts = DatasetTemplates(dataset_name, config) if config != None else DatasetTemplates(dataset_name)\n",
    "    prompt_name_list = list(all_prompts.name_to_id_mapping.keys())\n",
    "    prompt = all_prompts[prompt_name_list[prompt_idx]]\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6d813-628f-40fc-89b9-a04afd7c4b2a",
   "metadata": {},
   "source": [
    "## cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bb5b71e-99c5-4db6-9f16-012c9cf6971d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09a60ece-f315-4515-99ff-9b34d99af92f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cola_dataset = load_dataset(\"nyu-mll/glue\",\"cola\")\n",
    "print(cola_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85c88107-4c3f-4586-9c87-7863ef32feb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    cola_dataset[split] = cola_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "750c1554-82ca-4812-8436-8effe0f21be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'original_dataset_subset'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'original_dataset_subset'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'original_dataset_subset'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(cola_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f23ef65b-49fa-457e-abd0-5735b3e7c13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cola_dataset = cola_dataset.shuffle(seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b82a678-e850-4c66-a0e7-4c1f8a1dfefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cola_prompt_template = load_prompt(\"glue\", \"cola\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65c6a235-5bd0-4ffb-88fb-0f9a8fccfe30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = cola_dataset['train'][i]\n",
    "    input_txt, output_txt = cola_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a93ccaf5-7a4a-4034-bbe3-d15fba6a41dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = cola_dataset['train'][num_training_samples + i]\n",
    "    input_txt, output_txt = cola_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fda8e90-7cfc-4929-aa90-cb661e81bef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_cola_dataset = {\n",
    "    \"train\": train_set,\n",
    "    \"validation\": val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/cola.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_cola_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44ad733b-8df2-4bc7-9175-6345fe2f588b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 717, 'no': 283})\n",
      "Counter({'yes': 3540, 'no': 1460})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "cola_train_labels = [x['output'] for x in combined_cola_dataset[\"train\"]]\n",
    "cola_validation_labels = [x['output'] for x in combined_cola_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "cola_train_counter = Counter(cola_train_labels)\n",
    "cola_validation_counter = Counter(cola_validation_labels)\n",
    "\n",
    "print(cola_train_counter)\n",
    "print(cola_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56250e-b85e-4252-b238-b78849ab755e",
   "metadata": {},
   "source": [
    "# qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7cfceaf-3b5a-45a2-96ed-83d8cf910d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb2c414c-86cb-4de5-86f0-a9d3abb0c0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "qnli_dataset = load_dataset(\"nyu-mll/glue\",\"qnli\")\n",
    "print(qnli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e77af7a-42ed-4d64-8129-5c7cbba078dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    qnli_dataset[split] = qnli_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f230af5-f6bb-4f99-9a6a-108ebbccd27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_dataset = qnli_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52ef41b8-eb6e-45ea-bc37-28d28e65bb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_prompt_template = load_prompt(\"glue\", \"qnli\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a2a53b2-80a7-4378-ac5f-03002e3df90f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = qnli_dataset['train'][i]\n",
    "    input_txt, output_txt = qnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a06eeb83-dcbc-41fb-a15f-874ff9e52a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = qnli_dataset['validation'][i]\n",
    "    input_txt, output_txt = qnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qnli_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a580ad2c-5481-4cb9-a43a-285aaf2ba940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_qnli_dataset = {\n",
    "    \"train\": train_set,\n",
    "    \"validation\": qnli_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/qnli.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_qnli_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "723a3839-c41c-4510-80e5-695d785aba97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 507, 'no': 493})\n",
      "Counter({'no': 2501, 'yes': 2499})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "qnli_train_labels = [x['output'] for x in combined_qnli_dataset[\"train\"]]\n",
    "qnli_validation_labels = [x['output'] for x in combined_qnli_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "qnli_train_counter = Counter(qnli_train_labels)\n",
    "qnli_validation_counter = Counter(qnli_validation_labels)\n",
    "\n",
    "print(qnli_train_counter)\n",
    "print(qnli_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1209d-76a0-495e-8d9c-229677efe1cc",
   "metadata": {},
   "source": [
    "# qqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc6a90d4-79d7-47e5-bffe-a8c3b1e69a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35f992a7-db32-4ca9-a9dc-542d11c84fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 363846\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 40430\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 390965\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "qqp_dataset = load_dataset(\"nyu-mll/glue\",\"qqp\")\n",
    "print(qqp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00d32a6c-d929-426d-8c48-c188afd3497f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    qqp_dataset[split] = qqp_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0888245b-cfb9-4e53-b795-691f77147143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_dataset = qqp_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36d3a3e4-0cae-4630-9cd5-831249c118b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_prompt_template = load_prompt(\"glue\", \"qqp\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "963e87eb-0448-4f30-a796-8bc1c4c34636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = qqp_dataset['train'][i]\n",
    "    input_txt, output_txt = qqp_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qqp_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dcb7f1dc-1178-4522-be70-e49f42d6392a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = qqp_dataset['validation'][i]\n",
    "    input_txt, output_txt = qqp_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qqp_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "341104fb-0a85-4635-94be-3a030d92f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_qqp_dataset = {\n",
    "    \"train\": qqp_train_set,\n",
    "    \"validation\": qqp_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/qqp.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_qqp_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fc18364-c7b0-4a51-9ec1-9faef246baf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 628, 'yes': 372})\n",
      "Counter({'no': 3147, 'yes': 1853})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "qqp_train_labels = [x['output'] for x in combined_qqp_dataset[\"train\"]]\n",
    "qqp_validation_labels = [x['output'] for x in combined_qqp_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "qqp_train_counter = Counter(qqp_train_labels)\n",
    "qqp_validation_counter = Counter(qqp_validation_labels)\n",
    "\n",
    "print(qqp_train_counter)\n",
    "print(qqp_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b564d-fb4b-4fcc-b9c2-a2ec5753e075",
   "metadata": {},
   "source": [
    "# sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3aa459f3-a1c5-46a8-a559-4d09ed8780a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f8a0c32-49e4-4b08-a850-c21b108c83fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "sst2_dataset = load_dataset(\"nyu-mll/glue\",\"sst2\")\n",
    "print(sst2_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2efef3dc-2826-4d5f-a3f6-1dee57c35c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    sst2_dataset[split] = sst2_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54c8e8b5-9479-49f8-8729-829f177a9fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst2_dataset = sst2_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27aded19-ec4a-457d-ab74-b5b7182eb57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst2_prompt_template = load_prompt(\"glue\", \"sst2\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3aac7c7-6798-4748-a1a7-8db391dad17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst2_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = sst2_dataset['train'][i]\n",
    "    input_txt, output_txt = sst2_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    sst2_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49e915d3-5b53-4073-a731-a35561881113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst2_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = sst2_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = sst2_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    sst2_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a148fc6-adf3-462b-a0c9-8cbc105d156c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_sst2_dataset = {\n",
    "    \"train\": sst2_train_set,\n",
    "    \"validation\": sst2_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/sst2.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_sst2_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fca966f8-ff2b-477b-8026-23297df5cf1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 557, 'negative': 443})\n",
      "Counter({'positive': 2747, 'negative': 2253})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "sst2_train_labels = [x['output'] for x in combined_sst2_dataset[\"train\"]]\n",
    "sst2_validation_labels = [x['output'] for x in combined_sst2_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "sst2_train_counter = Counter(sst2_train_labels)\n",
    "sst2_validation_counter = Counter(sst2_validation_labels)\n",
    "\n",
    "print(sst2_train_counter)\n",
    "print(sst2_validation_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "924cce34-2677-4311-a46e-5047ee4d6a52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'klein , charming in comedies like american pie and dead-on in election , \\nQuestion: Was that sentence positive or negative? Answer:', 'output': 'positive', 'combined': 'klein , charming in comedies like american pie and dead-on in election , \\nQuestion: Was that sentence positive or negative? Answer:\\npositive', 'original_dataset_subset': 'train', 'original_idx': 32326}\n"
     ]
    }
   ],
   "source": [
    "print(combined_sst2_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f1803-05db-4fee-b064-b60748c913d4",
   "metadata": {},
   "source": [
    "# ag_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "445db628-1a4d-462b-aa2f-52f11e1ebbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "558eb3a3-2eab-4e45-b2ae-74f1d5e5a5db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ag_news_dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "print(ag_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4fa104a6-9f7c-440d-a27b-954f424dbcef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79160f8c2238457cb38234d96cbf6e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698173802e4f4e0faf3f32d44262ff8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in ['train', 'test']:\n",
    "    ag_news_dataset[split] = ag_news_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "506fcbbf-f7a9-42f9-a1be-713085cc1555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_dataset = ag_news_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f77f2411-2b20-440b-9c9b-046e883ca924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_prompt_template = load_prompt(\"ag_news\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d23a42f8-17b4-4473-b62c-bb26d1a6f532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = ag_news_dataset['train'][i]\n",
    "    input_txt, output_txt = ag_news_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        # \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    ag_news_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "480ab32b-766f-48a4-ade6-44ec53bda027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = ag_news_dataset['test'][i]\n",
    "    input_txt, output_txt = ag_news_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        # \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    ag_news_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "04d3886b-8986-4c77-894f-601e41cdf753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_ag_news_dataset = {\n",
    "    \"train\": ag_news_train_set,\n",
    "    \"validation\": ag_news_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/ag_news.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_ag_news_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d9382f4-1d16-491e-87aa-2a5d3e25c243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Science and technology': 271, 'World politics': 244, 'Sports': 243, 'Business': 242})\n",
      "Counter({'Sports': 1263, 'World politics': 1255, 'Business': 1248, 'Science and technology': 1234})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "ag_news_train_labels = [x['output'] for x in combined_ag_news_dataset[\"train\"]]\n",
    "ag_news_validation_labels = [x['output'] for x in combined_ag_news_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "ag_news_train_counter = Counter(ag_news_train_labels)\n",
    "ag_news_validation_counter = Counter(ag_news_validation_labels)\n",
    "\n",
    "print(ag_news_train_counter)\n",
    "print(ag_news_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032a144-c2df-41e3-b387-a02a52a7df17",
   "metadata": {},
   "source": [
    "# mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f45a7b97-7732-4407-9e98-db5dee6b41d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4f3a7e33-7546-4287-a9b2-e691ad7540aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 392702\n",
      "    })\n",
      "    validation_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9815\n",
      "    })\n",
      "    validation_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9832\n",
      "    })\n",
      "    test_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9796\n",
      "    })\n",
      "    test_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9847\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "mnli_dataset = load_dataset(\"nyu-mll/glue\",\"mnli\")\n",
    "print(mnli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ecc9708-1eac-4525-853d-36eabaecfdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation_matched']:\n",
    "    mnli_dataset[split] = mnli_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dcf6faa3-920e-4a4f-9929-a6fba209f9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_dataset = mnli_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "96131a9f-d6c9-4836-bf90-56a4e6912588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_prompt_template = load_prompt(\"glue/mnli\", prompt_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "656abc93-bc4a-4998-afd8-0991800011b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = mnli_dataset['train'][i]\n",
    "    input_txt, output_txt = mnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "    }\n",
    "    \n",
    "    mnli_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9543bb27-dbc6-4ba3-bb3b-7b7dc1bc5674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = mnli_dataset['validation_matched'][i]\n",
    "    input_txt, output_txt = mnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "    }\n",
    "    \n",
    "    mnli_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fe8dd350-5fa6-462f-a876-6e03995684e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_mnli_dataset = {\n",
    "    \"train\": mnli_train_set,\n",
    "    \"validation\": mnli_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/mnli.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_mnli_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83ce72ef-9f9f-4b28-abf8-bce40e553bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Maybe': 363, 'Yes': 337, 'No': 300})\n",
      "Counter({'Yes': 1765, 'Maybe': 1629, 'No': 1606})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "mnli_train_labels = [x['output'] for x in combined_mnli_dataset[\"train\"]]\n",
    "mnli_validation_labels = [x['output'] for x in combined_mnli_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "mnli_train_counter = Counter(mnli_train_labels)\n",
    "mnli_validation_counter = Counter(mnli_validation_labels)\n",
    "\n",
    "print(mnli_train_counter)\n",
    "print(mnli_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88806141-15ef-4662-96cd-c77eb3de1f10",
   "metadata": {},
   "source": [
    "# commonsense_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e486b949-c285-4c41-8e5c-a72456256a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cc814952-40ee-400f-a17a-ef448e05934b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 9741\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 1221\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 1140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "commonsense_qa_dataset = load_dataset(\"tau/commonsense_qa\")\n",
    "print(commonsense_qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7b0d5479-90e6-4c02-a7eb-517913079169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train']:\n",
    "    commonsense_qa_dataset[split] = commonsense_qa_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "acc69d42-b76e-48e3-ac8c-547cb58804ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commonsense_qa_dataset = commonsense_qa_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3044dc6a-79c4-47e1-ab25-69a0e368605d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commonsense_qa_prompt_template = load_prompt(\"commonsense_qa\", prompt_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "30488570-afc2-4656-8350-99cf3ca7dc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Given the following options, what do you think is the correct answer to the question below:\\n\\nI needed to send a piece of mail, where did I go?\\n\\nOptions:\\n\\n- A: table\\n\\n- B: post office\\n\\n- C: neighbor's house\\n\\n- D: railway station\",\n",
       " 'B']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonsense_qa_prompt_template.apply(commonsense_qa_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ce612ee6-7a65-4a68-af43-2ed12da1719d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commonsense_qa_dataset = commonsense_qa_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "95923d4c-f6a6-462d-b807-affdce03aa6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commonsense_qa_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = commonsense_qa_dataset['train'][i]\n",
    "    input_txt, output_txt = commonsense_qa_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_id\": dataset_element['id']\n",
    "    }\n",
    "    \n",
    "    commonsense_qa_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f8f4ba3f-24af-4846-9624-e87f0d722d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commonsense_qa_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = commonsense_qa_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = commonsense_qa_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_id\": dataset_element['id']\n",
    "\n",
    "    }\n",
    "    \n",
    "    commonsense_qa_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3bea58d9-36d9-458a-96ce-bb5d91638ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_commonsense_qa_dataset = {\n",
    "    \"train\": commonsense_qa_train_set,\n",
    "    \"validation\": commonsense_qa_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/commonsense_qa.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_commonsense_qa_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5dbf9e87-cfe3-4ecc-9122-5230f2d331f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'D': 211, 'B': 210, 'A': 203, 'C': 198, 'E': 178})\n",
      "Counter({'D': 1038, 'B': 1013, 'C': 995, 'E': 988, 'A': 966})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "commonsense_qa_train_labels = [x['output'] for x in combined_commonsense_qa_dataset[\"train\"]]\n",
    "commonsense_qa_validation_labels = [x['output'] for x in combined_commonsense_qa_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "commonsense_qa_train_counter = Counter(commonsense_qa_train_labels)\n",
    "commonsense_qa_validation_counter = Counter(commonsense_qa_validation_labels)\n",
    "\n",
    "print(commonsense_qa_train_counter)\n",
    "print(commonsense_qa_validation_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "527c62a1-f4df-42e9-8e29-22244b6233f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following options, what do you think is the correct answer to the question below:\n",
      "\n",
      "A school is necessary for every one of these. What are they?\n",
      "\n",
      "Options:\n",
      "\n",
      "- A: every city\n",
      "\n",
      "- B: community\n",
      "\n",
      "- C: playground\n",
      "\n",
      "- D: residential neighborhood\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "print(commonsense_qa_train_set[0]['combined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa360da0-1d80-4480-9654-0c3e07554e36",
   "metadata": {},
   "source": [
    "# mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a35ab366-f868-4c6b-8ff6-3b931afd7da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3e75a4d9-880c-49c5-96d4-06c5536100b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 14042\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 1531\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 285\n",
      "    })\n",
      "    auxiliary_train: Dataset({\n",
      "        features: ['question', 'subject', 'choices', 'answer'],\n",
      "        num_rows: 99842\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "mmlu_dataset = load_dataset(\"cais/mmlu\", 'all')\n",
    "print(mmlu_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "eab7cdc1-9c6b-4447-918f-d2760e336ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['test']:\n",
    "    mmlu_dataset[split] = mmlu_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "64105401-2f1d-4d7a-942a-b3b2b4a1beb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmlu_dataset = mmlu_dataset.shuffle(seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4678651b-cf95-4b9d-8eec-3ba04abe714f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"The demand curve for a perfectly competitive firm's product is\", 'subject': 'high_school_microeconomics', 'choices': ['downward sloping and equal to the market demand curve.', 'perfectly elastic.', 'perfectly inelastic.', 'kinked at the going market price.'], 'answer': 1, 'original_dataset_subset': 'test'}\n"
     ]
    }
   ],
   "source": [
    "print(mmlu_dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "eca2c56b-1cb6-4541-a71c-22b1fcf71a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmlu_train_set = []\n",
    "num_training_samples = 1000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = mmlu_dataset['test'][i]\n",
    "    \n",
    "    # generate input txt and output txt\n",
    "    letters = ['A', 'B', 'C', 'D']\n",
    "    choices = dataset_element['choices']\n",
    "    \n",
    "    input_txt = f\"{dataset_element['question']}\\n\\nA: {choices[0]}\\nB: {choices[1]}\\nC: {choices[2]}\\nD: {choices[3]}\\nAnswer:\"\n",
    "    \n",
    "    answer_idx = dataset_element['answer']\n",
    "    output_txt = letters[answer_idx]\n",
    "    \n",
    "        \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"subject\": dataset_element['subject']\n",
    "    }\n",
    "    \n",
    "    mmlu_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "80f6369e-9dc0-4fd3-9c28-9ea4d00bc004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The demand curve for a perfectly competitive firm's product is\n",
      "\n",
      "A: downward sloping and equal to the market demand curve.\n",
      "B: perfectly elastic.\n",
      "C: perfectly inelastic.\n",
      "D: kinked at the going market price.\n",
      "Answer:\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "print(mmlu_train_set[0]['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "176b88a6-794e-4731-b8c3-1ac05ee7e4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmlu_val_set = []\n",
    "num_val_samples = 5000\n",
    "\n",
    "for i in range(num_val_samples):\n",
    "    dataset_element = mmlu_dataset['test'][i + num_training_samples]\n",
    "    \n",
    "    # generate input txt and output txt\n",
    "    letters = ['A', 'B', 'C', 'D']\n",
    "    choices = dataset_element['choices']\n",
    "    \n",
    "    input_txt = f\"{dataset_element['question']}\\n\\nA: {choices[0]}\\nB: {choices[1]}\\nC: {choices[2]}\\nD: {choices[3]}\\nAnswer:\"\n",
    "    \n",
    "    answer_idx = dataset_element['answer']\n",
    "    output_txt = letters[answer_idx]\n",
    "    \n",
    "        \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"subject\": dataset_element['subject']\n",
    "    }\n",
    "    \n",
    "    mmlu_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fb65de2c-c811-41dc-9665-d33bc7c16d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_mmlu_dataset = {\n",
    "    \"train\": mmlu_train_set,\n",
    "    \"validation\": mmlu_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/mmlu.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_mmlu_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2a5af512-7f6e-4907-a457-aa3c61a6fd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'B': 263, 'C': 252, 'D': 243, 'A': 242})\n",
      "Counter({'D': 1346, 'C': 1281, 'B': 1207, 'A': 1166})\n"
     ]
    }
   ],
   "source": [
    "mmlu_train_labels = [x['output'] for x in combined_mmlu_dataset[\"train\"]]\n",
    "mmlu_validation_labels = [x['output'] for x in combined_mmlu_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "mmlu_train_counter = Counter(mmlu_train_labels)\n",
    "mmlu_validation_counter = Counter(mmlu_validation_labels)\n",
    "\n",
    "print(mmlu_train_counter)\n",
    "print(mmlu_validation_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3f0e6-d8fd-4c30-8e35-d9c080036db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
