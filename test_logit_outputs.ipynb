{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7a06ef-8ca7-4e30-accb-6635281f4c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from model_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20da8f26-c58a-49aa-9fc8-22fc37b68e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fcd2c6f7fa4174a6e5af0fddcecd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer padding side: left\n",
      "Model and tokenizer for meta-llama/Llama-2-7b-hf loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer('meta-llama/Llama-2-7b-hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3666e3fe-a341-48d7-ab50-bc69198b4c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompts(dataset_name, k, num_eval_items=5000):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    train_set = dataset['train']\n",
    "    eval_set = dataset['validation']\n",
    "\n",
    "    prompts, answers = [], []\n",
    "\n",
    "    # load icl indices\n",
    "    icl_indices = load_icl_indices(k)\n",
    "    for eval_idx in range(num_eval_items):\n",
    "        prompt = \"\"\n",
    "        indices = icl_indices[str(eval_idx)]\n",
    "\n",
    "        for idx in indices:\n",
    "            prompt += train_set[idx]['combined'] + \"\\n\\n\"\n",
    "\n",
    "        query = eval_set[eval_idx]['input'] + \"\\n\"\n",
    "        answer = eval_set[eval_idx]['output']\n",
    "\n",
    "        prompt += query\n",
    "        prompts.append(prompt)\n",
    "        answers.append(answer)\n",
    "\n",
    "    return prompts, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e570df7-41fd-4fbc-9308-6fb4dc19f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from datasets/mnli.json\n",
      "Dataset loaded successfully from datasets/mnli.json\n",
      "Loading ICL indices from data_indices/icl_indices_10_shot.json\n",
      "ICL indices loaded successfully from data_indices/icl_indices_10_shot.json\n"
     ]
    }
   ],
   "source": [
    "# prepare prompts\n",
    "prompts, answers = generate_prompts('mnli', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e70d29b1-c48c-48d8-bf22-c296e6e57e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65a90a13-336f-4abd-8c0f-1033fe602d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the boy is still very young\"  Are we justified in saying that \"THe girl is old.\"? Yes, no, or maybe?\n",
      "No\n",
      "\n",
      "John Knox was a tenant here from 1651 to 1672, but the house was owned by James Mosman, a royal goldsmith, and his wife Mariota Arres; a plaque bearing their initials can be seen on the outer wall. Are we justified in saying that \"Houses were only owned by the people who lived in them in the 1600s.\"? Yes, no, or maybe?\n",
      "No\n",
      "\n",
      "Permanently boosting the rate of GDP growth would require ever-increasing relative shares of saving and Are we justified in saying that \"Savings would have to increase more and more in order to boost the rate of GDP growth.\"? Yes, no, or maybe?\n",
      "Yes\n",
      "\n",
      "A variety of themes are space, health, communications, agriculture, etc. Are we justified in saying that \"The themes change occasionally.\"? Yes, no, or maybe?\n",
      "Maybe\n",
      "\n",
      "The following year, acting with what Prime Minister Antonio Salandra acknowledged to be  sacro egoismo,  Italy signed a secret treaty to enter the war on the side of Britain, France, and Russia in exchange for the post-war annexation of Austrian-held Trento, South Tyrol (now Alto Adige), and Trieste. Are we justified in saying that \"Britain, France, Russia, and Italy won the war.\"? Yes, no, or maybe?\n",
      "Maybe\n",
      "\n",
      "On the lake's west shore, the people of Sal?? (where Gaspare Bertolotti is regarded as the originator of the violin) suggest that his design was inspired by the contours of the lake. Are we justified in saying that \"Gaspare Bertolotti, who created the violin, designed it to resemble a lake.\"? Yes, no, or maybe?\n",
      "Yes\n",
      "\n",
      "it's it's what you do after that that that that that uh it that really judges how far you're going to go with a degree Are we justified in saying that \"The possibilities are boundless.\"? Yes, no, or maybe?\n",
      "Maybe\n",
      "\n",
      "Get rid of all guns? Are we justified in saying that \"Mass-produce guns and give them to everyone.\"? Yes, no, or maybe?\n",
      "No\n",
      "\n",
      "oh it is i there's so Are we justified in saying that \"it has always been. \"? Yes, no, or maybe?\n",
      "Maybe\n",
      "\n",
      "A Nice Head-Shrinking Never Hurt  Based on the presidential press conference this week, Gigot senses that Clinton may be having difficulty separating myth and reality. Are we justified in saying that \"Gigot believes that Clinton is struggling to separate myth and reality.\"? Yes, no, or maybe?\n",
      "Yes\n",
      "\n",
      "Clean shaven, I think and dark.\" Are we justified in saying that \"Unshaven, and bright.\"? Yes, no, or maybe?\n",
      "\n",
      "-----------\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "print(prompts[7])\n",
    "print(\"-----------\")\n",
    "print(answers[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a43ff2cb-0d91-4a03-80c6-a07b4bf17390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding side: left\n"
     ]
    }
   ],
   "source": [
    "# run activations using regular hf api\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"padding side: {tokenizer.padding_side}\")\n",
    "\n",
    "\n",
    "inputs = tokenizer([prompts[7]], padding=True, return_tensors=\"pt\").to(device)\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa8a5fe1-29b7-4f5f-9158-cafc57cb9259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 684, 32000])\n"
     ]
    }
   ],
   "source": [
    "# run activations using custom method\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "175fe4e4-e34c-4e5d-8fc4-56f08ea0e1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_token_logits = logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dea91ada-2161-484d-9a20-db88f0b07840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000])\n"
     ]
    }
   ],
   "source": [
    "print(final_token_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e89658fb-539c-42e2-ba9b-f6575b1a09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['Sports', 'Business', 'Science and technology', 'World politics']\n",
    "labels = ['Yes', 'No', 'Maybe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "afeac8be-f46e-4152-9e7f-168219d9e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values, top_indices = torch.topk(final_token_logits, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaa80c54-6580-44f8-93f1-6132b1e1a03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24.3727, 24.2131, 23.3707, 19.7781], device='cuda:0',\n",
       "       grad_fn=<TopkBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c074ac7-5ff1-4040-bd1a-6f6db8caff11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "Maybe\n",
      "Yes\n",
      "Pro\n"
     ]
    }
   ],
   "source": [
    "for index in top_indices:\n",
    "    print(tokenizer.decode(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "089566e7-82a5-4935-b4c0-a42f012d2db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3782, 22762,  8241,  1184], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "35239aac-b695-4c83-a0c5-40730c5b0b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3869]\n",
      "Yes\n",
      "logit value: 11.518129348754883\n",
      "softmaxed logit value: tensor([1.])\n",
      "---------\n",
      "[1939]\n",
      "No\n",
      "logit value: 8.69173812866211\n",
      "softmaxed logit value: tensor([1.])\n",
      "---------\n",
      "[7198]\n",
      "Maybe\n",
      "logit value: 14.872579574584961\n",
      "softmaxed logit value: tensor([1.])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    encoded_text = tokenizer.encode(label, add_special_tokens=False)\n",
    "    print(encoded_text)\n",
    "    print(tokenizer.decode(encoded_text))\n",
    "    \n",
    "    logit_value = final_token_logits[encoded_text[0]]\n",
    "    print(f\"logit value: {logit_value}\")\n",
    "    \n",
    "    # Apply softmax along the appropriate dimension (dim=0 here since logit_value is likely 1D)\n",
    "    softmaxed_logit_value = torch.softmax(torch.Tensor([logit_value]), dim=0)\n",
    "    print(f\"softmaxed logit value: {softmaxed_logit_value}\")\n",
    "    \n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4aa1ce1c-fd81-4e28-80d6-60933b5be88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maybe\\n\\nthe the']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_new_texts(model, tokenizer, texts=[prompts[7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b221a7-1546-43c3-82f8-9d7c11e4e83d",
   "metadata": {},
   "source": [
    "# investigating the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0e929fc-59f8-4d26-8f6a-cea67396ab3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "\n",
      "{'prompt': 'And the boy is still very young\"  Are we justified in saying that \"THe girl is old.\"? Yes, no, or maybe?\\nNo\\n\\nJohn Knox was a tenant here from 1651 to 1672, but the house was owned by James Mosman, a royal goldsmith, and his wife Mariota Arres; a plaque bearing their initials can be seen on the outer wall. Are we justified in saying that \"Houses were only owned by the people who lived in them in the 1600s.\"? Yes, no, or maybe?\\nNo\\n\\nPermanently boosting the rate of GDP growth would require ever-increasing relative shares of saving and Are we justified in saying that \"Savings would have to increase more and more in order to boost the rate of GDP growth.\"? Yes, no, or maybe?\\nYes\\n\\nA variety of themes are space, health, communications, agriculture, etc. Are we justified in saying that \"The themes change occasionally.\"? Yes, no, or maybe?\\nMaybe\\n\\nThe following year, acting with what Prime Minister Antonio Salandra acknowledged to be  sacro egoismo,  Italy signed a secret treaty to enter the war on the side of Britain, France, and Russia in exchange for the post-war annexation of Austrian-held Trento, South Tyrol (now Alto Adige), and Trieste. Are we justified in saying that \"Britain, France, Russia, and Italy won the war.\"? Yes, no, or maybe?\\nMaybe\\n\\nOn the lake\\'s west shore, the people of Sal?? (where Gaspare Bertolotti is regarded as the originator of the violin) suggest that his design was inspired by the contours of the lake. Are we justified in saying that \"Gaspare Bertolotti, who created the violin, designed it to resemble a lake.\"? Yes, no, or maybe?\\nYes\\n\\nit\\'s it\\'s what you do after that that that that that uh it that really judges how far you\\'re going to go with a degree Are we justified in saying that \"The possibilities are boundless.\"? Yes, no, or maybe?\\nMaybe\\n\\nGet rid of all guns? Are we justified in saying that \"Mass-produce guns and give them to everyone.\"? Yes, no, or maybe?\\nNo\\n\\noh it is i there\\'s so Are we justified in saying that \"it has always been. \"? Yes, no, or maybe?\\nMaybe\\n\\nA Nice Head-Shrinking Never Hurt  Based on the presidential press conference this week, Gigot senses that Clinton may be having difficulty separating myth and reality. Are we justified in saying that \"Gigot believes that Clinton is struggling to separate myth and reality.\"? Yes, no, or maybe?\\nYes\\n\\nClean shaven, I think and dark.\" Are we justified in saying that \"Unshaven, and bright.\"? Yes, no, or maybe?\\n', 'target': 'No', 'generated_output': 'No\\n\\n\"I\\'', 'score': True, 'parsed_str': 'No', 'index': 7}\n",
      "\n",
      "{'logits': {'Maybe': 14.872567176818848, 'Yes': 11.518133163452148, 'No': 8.691739082336426}, 'probabilities': {'Maybe': 3.257923890487291e-05, 'Yes': 1.1379645457054721e-06, 'No': 6.739713143133486e-08}, 'is_correct': False}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "dataset_name = \"mnli\"\n",
    "k = 10\n",
    "\n",
    "\n",
    "# load the generations\n",
    "generations_path = Path(f\"results/icl/accuracy_results/{model_name}/{dataset_name}/{k}-shot/generations.json\")\n",
    "\n",
    "with open(generations_path, 'r') as f:\n",
    "    generations_data = json.load(f)\n",
    "\n",
    "\n",
    "# load the logit data\n",
    "logit_data_path = Path(f\"results/icl/logits/{model_name}/{dataset_name}/{k}-shot/logit_data.json\")\n",
    "\n",
    "with open(logit_data_path, 'r') as f:\n",
    "    logit_data = json.load(f)\n",
    "\n",
    "for i in range(len(generations_data)):\n",
    "    generation_correct = generations_data[i]['score']\n",
    "    logit_accurate = logit_data[str(i)]['is_correct']\n",
    "    \n",
    "    if generation_correct and not logit_accurate:\n",
    "        print(i)\n",
    "        \n",
    "        print()\n",
    "        print(generations_data[i])\n",
    "        print()\n",
    "        print(logit_data[str(i)])\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f2f6f-958f-463a-8da3-400612ec18e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
