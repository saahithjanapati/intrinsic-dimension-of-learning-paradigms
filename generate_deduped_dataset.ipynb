{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea526ad-cc57-4ce0-80f0-a4aeffc476d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Datasets to make:\n",
    "\n",
    "- [x] cola\n",
    "- [x] qnli\n",
    "- [x] qqp\n",
    "- [x] sst2\n",
    "- [x] ag_news\n",
    "- [x] commonsense_qa\n",
    "- [x] mnli\n",
    "- [x] mmlu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec8fde1-7dad-4569-882b-80d2c8248a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from promptsource.templates import DatasetTemplates\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425bceb5-9503-4540-a8a2-f5190f899f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_prompt(dataset_name, config=None, prompt_idx=0):\n",
    "    \"\"\"this function loads a test prompt for a specified dataset to see if promptSource supports it\"\"\"\n",
    "    all_prompts = DatasetTemplates(dataset_name, config) if config != None else DatasetTemplates(dataset_name)\n",
    "    prompt_name_list = list(all_prompts.name_to_id_mapping.keys())\n",
    "    prompt = all_prompts[prompt_name_list[prompt_idx]]\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56250e-b85e-4252-b238-b78849ab755e",
   "metadata": {},
   "source": [
    "# qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7cfceaf-3b5a-45a2-96ed-83d8cf910d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb2c414c-86cb-4de5-86f0-a9d3abb0c0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "qnli_dataset = load_dataset(\"nyu-mll/glue\",\"qnli\")\n",
    "print(qnli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e77af7a-42ed-4d64-8129-5c7cbba078dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    qnli_dataset[split] = qnli_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f230af5-f6bb-4f99-9a6a-108ebbccd27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_dataset = qnli_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52ef41b8-eb6e-45ea-bc37-28d28e65bb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_prompt_template = load_prompt(\"glue\", \"qnli\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a2a53b2-80a7-4378-ac5f-03002e3df90f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "num_training_samples = 100000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = qnli_dataset['train'][i]\n",
    "    input_txt, output_txt = qnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbcfff90-9ca3-4908-a4b8-604b7cd30b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Apparently the sailor did not connect with the soldier, as Mahan believed he was innovating the term Middle East.\\nDoes that sentence have all you need to answer the question \"Who did not connect with the soldier?\"?',\n",
       " 'output': 'yes',\n",
       " 'combined': 'Apparently the sailor did not connect with the soldier, as Mahan believed he was innovating the term Middle East.\\nDoes that sentence have all you need to answer the question \"Who did not connect with the soldier?\"?\\nyes',\n",
       " 'original_dataset_subset': 'train',\n",
       " 'original_idx': 99928}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06eeb83-dcbc-41fb-a15f-874ff9e52a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnli_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = qnli_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = qnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qnli_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a580ad2c-5481-4cb9-a43a-285aaf2ba940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_qnli_dataset = {\n",
    "    \"train\": train_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/deduped_train_qnli.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_qnli_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "723a3839-c41c-4510-80e5-695d785aba97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 50031, 'no': 49969})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "# qnli_train_labels = [x['output'] for x in combined_qnli_dataset[\"train\"]]\n",
    "qnli_validation_labels = [x['output'] for x in combined_qnli_dataset[\"train\"]]\n",
    "\n",
    "\n",
    "# qnli_train_counter = Counter(qnli_train_labels)\n",
    "qnli_validation_counter = Counter(qnli_validation_labels)\n",
    "\n",
    "# print(qnli_train_counter)\n",
    "print(qnli_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1209d-76a0-495e-8d9c-229677efe1cc",
   "metadata": {},
   "source": [
    "# qqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc6a90d4-79d7-47e5-bffe-a8c3b1e69a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35f992a7-db32-4ca9-a9dc-542d11c84fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 363846\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 40430\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 390965\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "qqp_dataset = load_dataset(\"nyu-mll/glue\",\"qqp\")\n",
    "print(qqp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00d32a6c-d929-426d-8c48-c188afd3497f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    qqp_dataset[split] = qqp_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0888245b-cfb9-4e53-b795-691f77147143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_dataset = qqp_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36d3a3e4-0cae-4630-9cd5-831249c118b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_prompt_template = load_prompt(\"glue\", \"qqp\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "963e87eb-0448-4f30-a796-8bc1c4c34636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_train_set = []\n",
    "num_training_samples = 100000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = qqp_dataset['train'][i]\n",
    "    input_txt, output_txt = qqp_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qqp_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea2c2bbc-9664-4a9c-8da8-e9e80ee78b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'I\\'m an administrator on the website Quora. There are two posts, one that asks \"What would Rhaegar and Jon have thought of each other?\" and another that asks \"What is the amount of torque a 2000 Jeep Cherokee can output?\". I can merge questions if they are asking the same thing. Can I merge these two questions?', 'output': 'no', 'combined': 'I\\'m an administrator on the website Quora. There are two posts, one that asks \"What would Rhaegar and Jon have thought of each other?\" and another that asks \"What is the amount of torque a 2000 Jeep Cherokee can output?\". I can merge questions if they are asking the same thing. Can I merge these two questions?\\nno', 'original_dataset_subset': 'train', 'original_idx': 260796}\n"
     ]
    }
   ],
   "source": [
    "print(qqp_train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcb7f1dc-1178-4522-be70-e49f42d6392a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qqp_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = qqp_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = qqp_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    qqp_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "341104fb-0a85-4635-94be-3a030d92f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_qqp_dataset = {\n",
    "    \"train\": qqp_train_set,\n",
    "    # \"validation\": qqp_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/deduped_train_qqp.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_qqp_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9fc18364-c7b0-4a51-9ec1-9faef246baf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 63074, 'yes': 36926})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "# qqp_train_labels = [x['output'] for x in combined_qqp_dataset[\"train\"]]\n",
    "qqp_validation_labels = [x['output'] for x in combined_qqp_dataset[\"train\"]]\n",
    "\n",
    "\n",
    "# qqp_train_counter = Counter(qqp_train_labels)\n",
    "qqp_validation_counter = Counter(qqp_validation_labels)\n",
    "\n",
    "# print(qqp_train_counter)\n",
    "print(qqp_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f1803-05db-4fee-b064-b60748c913d4",
   "metadata": {},
   "source": [
    "# ag_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "445db628-1a4d-462b-aa2f-52f11e1ebbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "558eb3a3-2eab-4e45-b2ae-74f1d5e5a5db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ag_news_dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "print(ag_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fa104a6-9f7c-440d-a27b-954f424dbcef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'test']:\n",
    "    ag_news_dataset[split] = ag_news_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "506fcbbf-f7a9-42f9-a1be-713085cc1555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_dataset = ag_news_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f77f2411-2b20-440b-9c9b-046e883ca924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_prompt_template = load_prompt(\"ag_news\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d23a42f8-17b4-4473-b62c-bb26d1a6f532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_train_set = []\n",
    "num_training_samples = 100000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = ag_news_dataset['train'][i]\n",
    "    input_txt, output_txt = ag_news_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        # \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    ag_news_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d653b0e7-6ebd-4c84-8b8d-5835bb38f3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What label best describes this news article?\\nBangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.',\n",
       " 'output': 'World politics',\n",
       " 'combined': 'What label best describes this news article?\\nBangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.\\nWorld politics',\n",
       " 'original_dataset_subset': 'train'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news_train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "480ab32b-766f-48a4-ade6-44ec53bda027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag_news_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = ag_news_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = ag_news_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "        # \"original_idx\": dataset_element['idx']\n",
    "    }\n",
    "    \n",
    "    ag_news_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04d3886b-8986-4c77-894f-601e41cdf753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_ag_news_dataset = {\n",
    "    \"train\": ag_news_train_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/deduped_train_ag_news.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_ag_news_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d9382f4-1d16-491e-87aa-2a5d3e25c243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Sports': 25078, 'Science and technology': 25018, 'Business': 25004, 'World politics': 24900})\n"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "# ag_news_train_labels = [x['output'] for x in combined_ag_news_dataset[\"train\"]]\n",
    "ag_news_validation_labels = [x['output'] for x in combined_ag_news_dataset[\"train\"]]\n",
    "\n",
    "\n",
    "# ag_news_train_counter = Counter(ag_news_train_labels)\n",
    "ag_news_validation_counter = Counter(ag_news_validation_labels)\n",
    "\n",
    "# print(ag_news_train_counter)\n",
    "print(ag_news_validation_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032a144-c2df-41e3-b387-a02a52a7df17",
   "metadata": {},
   "source": [
    "# mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f45a7b97-7732-4407-9e98-db5dee6b41d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add the original split name to each example\n",
    "def add_original_split(example, split_name):\n",
    "    example['original_dataset_subset'] = split_name\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4f3a7e33-7546-4287-a9b2-e691ad7540aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 392702\n",
      "    })\n",
      "    validation_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9815\n",
      "    })\n",
      "    validation_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9832\n",
      "    })\n",
      "    test_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9796\n",
      "    })\n",
      "    test_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9847\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "mnli_dataset = load_dataset(\"nyu-mll/glue\",\"mnli\")\n",
    "print(mnli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ecc9708-1eac-4525-853d-36eabaecfdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'validation_matched']:\n",
    "    mnli_dataset[split] = mnli_dataset[split].map(lambda x: add_original_split(x, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcf6faa3-920e-4a4f-9929-a6fba209f9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_dataset = mnli_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96131a9f-d6c9-4836-bf90-56a4e6912588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_prompt_template = load_prompt(\"glue/mnli\", prompt_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "656abc93-bc4a-4998-afd8-0991800011b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_train_set = []\n",
    "num_training_samples = 100000\n",
    "\n",
    "for i in range(num_training_samples):\n",
    "    dataset_element = mnli_dataset['train'][i]\n",
    "    input_txt, output_txt = mnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "    }\n",
    "    \n",
    "    mnli_train_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32fd1957-3665-406f-b399-8af90d252598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I\\'ll hurry over that part. Are we justified in saying that \"\"I\\'ll be quick with that part.\"\"? Yes, no, or maybe?',\n",
       " 'output': 'Yes',\n",
       " 'combined': 'I\\'ll hurry over that part. Are we justified in saying that \"\"I\\'ll be quick with that part.\"\"? Yes, no, or maybe?\\nYes',\n",
       " 'original_dataset_subset': 'train'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9543bb27-dbc6-4ba3-bb3b-7b7dc1bc5674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnli_val_set = []\n",
    "num_eval_samples = 5000\n",
    "\n",
    "for i in range(num_eval_samples):\n",
    "    dataset_element = mnli_dataset['train'][i + num_training_samples]\n",
    "    input_txt, output_txt = mnli_prompt_template.apply(dataset_element)\n",
    "    \n",
    "    dataset_obj = {\n",
    "        \"input\": input_txt,\n",
    "        \"output\": output_txt,\n",
    "        \"combined\": input_txt + \"\\n\" + output_txt,\n",
    "        \"original_dataset_subset\": dataset_element['original_dataset_subset'],\n",
    "    }\n",
    "    \n",
    "    mnli_val_set.append(dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe8dd350-5fa6-462f-a876-6e03995684e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_mnli_dataset = {\n",
    "    \"train\": mnli_train_set,\n",
    "    # \"validation\": mnli_val_set\n",
    "}\n",
    "\n",
    "save_path = Path(f\"datasets/deduped_train_mnli.json\")\n",
    "with save_path.open(\"w\") as f:\n",
    "    json.dump(combined_mnli_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83ce72ef-9f9f-4b28-abf8-bce40e553bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# show the label distribution of both the train and validation sets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mnli_train_labels \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m combined_mnli_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m mnli_validation_labels \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcombined_mnli_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m      6\u001b[0m mnli_train_counter \u001b[38;5;241m=\u001b[39m Counter(mnli_train_labels)\n\u001b[1;32m      7\u001b[0m mnli_validation_counter \u001b[38;5;241m=\u001b[39m Counter(mnli_validation_labels)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'validation'"
     ]
    }
   ],
   "source": [
    "# show the label distribution of both the train and validation sets\n",
    "mnli_train_labels = [x['output'] for x in combined_mnli_dataset[\"train\"]]\n",
    "mnli_validation_labels = [x['output'] for x in combined_mnli_dataset[\"validation\"]]\n",
    "\n",
    "\n",
    "mnli_train_counter = Counter(mnli_train_labels)\n",
    "mnli_validation_counter = Counter(mnli_validation_labels)\n",
    "\n",
    "print(mnli_train_counter)\n",
    "print(mnli_validation_counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
